{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1:\n",
      " \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "t1.numpy:\n",
      " [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "t2:\n",
      " \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "t3:\n",
      " \n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "t4:\n",
      " \n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.LongTensor of size 2x3]\n",
      "\n",
      "t1:\n",
      " \n",
      "   1    1    1\n",
      "   1    1  999\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "t5:\n",
      " \n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      " 0  0  0  0\n",
      "[torch.DoubleTensor of size 3x4]\n",
      "\n",
      "t6:\n",
      " \n",
      " 1.2235 -0.1828 -0.6240\n",
      "-1.7459 -1.0781 -0.0315\n",
      "-1.1519  0.0393  1.1664\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n",
      "input:\n",
      " Variable containing:\n",
      "-1.3099 -0.0280 -0.4209  0.2763  0.2660\n",
      "-0.4541  0.2253 -0.7899  0.8581 -0.9677\n",
      " 0.7413  0.6453 -0.1231 -0.9948 -1.7731\n",
      "[torch.FloatTensor of size 3x5]\n",
      "\n",
      "t7:\n",
      " \n",
      "(0 ,.,.) = \n",
      "   3   1   3   0   0   2   3   1\n",
      "   0   2   1   1   0   3   0   2\n",
      "   2   3   3   1   3   2   0   3\n",
      "   2   0   1   3   2   2   2   2\n",
      "   1   3   2   2   2   1   0   0\n",
      "   0   1   3   1   1   2   0   3\n",
      "   1   2   0   1   1   1   3   0\n",
      "   3   3   1   1   0   3   0   3\n",
      "\n",
      "(1 ,.,.) = \n",
      "   3   3   3   3   2   0   1   3\n",
      "   3   3   3   3   3   2   2   0\n",
      "   0   1   3   2   2   2   3   3\n",
      "   1   3   1   2   0   3   2   0\n",
      "   1   3   1   3   2   1   0   0\n",
      "   1   3   0   2   0   0   3   1\n",
      "   3   3   3   0   0   0   2   1\n",
      "   1   1   0   3   1   0   2   3\n",
      "\n",
      "(2 ,.,.) = \n",
      "   2   3   2   0   3   2   2   1\n",
      "   2   2   2   1   0   0   1   0\n",
      "   1   3   1   0   0   1   0   2\n",
      "   3   1   2   0   3   1   2   1\n",
      "   3   3   3   0   0   0   3   2\n",
      "   1   3   3   2   3   3   3   1\n",
      "   3   2   3   3   2   3   0   2\n",
      "   2   2   0   2   0   3   0   3\n",
      "\n",
      "(3 ,.,.) = \n",
      "   0   2   1   0   3   2   2   3\n",
      "   0   2   3   2   1   1   0   1\n",
      "   2   1   2   1   1   1   2   2\n",
      "   1   3   2   2   1   2   1   1\n",
      "   3   2   3   1   0   0   2   3\n",
      "   3   2   1   2   3   2   2   0\n",
      "   1   2   2   0   2   1   1   3\n",
      "   3   2   3   3   3   3   0   1\n",
      "\n",
      "(4 ,.,.) = \n",
      "   0   3   3   3   0   2   2   3\n",
      "   1   0   3   3   1   3   3   3\n",
      "   1   1   0   0   3   0   3   0\n",
      "   0   1   0   0   3   1   2   1\n",
      "   3   3   3   2   2   3   1   2\n",
      "   3   3   0   2   2   1   0   3\n",
      "   1   0   1   3   3   2   0   2\n",
      "   1   2   0   0   2   1   1   0\n",
      "[torch.LongTensor of size 5x8x8]\n",
      "\n",
      "t8:\n",
      " \n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n",
      "t9:\n",
      " \n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "t8:\n",
      " \n",
      " 1  1\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "t1 = tr.Tensor(np.ones((2,3)))\n",
    "print('t1:\\n',t1)\n",
    "print('t1.numpy:\\n',t1.numpy())\n",
    "t2 = tr.ones((2,3))\n",
    "print('t2:\\n',t2)\n",
    "t3 = tr.zeros((2,3))\n",
    "print('t3:\\n',t3)\n",
    "t4 = t1.long()\n",
    "# .short, .int,\n",
    "print('t4:\\n',t4)\n",
    "t1[1,2] = 999\n",
    "print('t1:\\n',t1)\n",
    "\n",
    "# the from_numpy will inherit the type of numpy array.\n",
    "t5=tr.from_numpy(np.zeros((3,4),dtype='float64'))\n",
    "print('t5:\\n',t5)\n",
    "\n",
    "t6 = tr.randn((3,3))\n",
    "print('t6:\\n',t6)\n",
    "\n",
    "N, C = 5, 4\n",
    "t7 = tr.LongTensor(N, 8, 8).random_(0, C)\n",
    "input = tr.autograd.Variable(tr.randn(3, 5))\n",
    "print('input:\\n',input)\n",
    "print('t7:\\n',t7)\n",
    "\n",
    "t8 = tr.FloatTensor([np.ones((2,)),np.ones((2,)),np.ones((2,))])\n",
    "print('t8:\\n',t8)\n",
    "\n",
    "t9 = t8.view(-1)\n",
    "print('t9:\\n',t9)\n",
    "print('t8:\\n',t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t3.cuda() can put data to gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tr.FloatTensor([[1,2],[3,4]])\n",
    "v1 = tr.autograd.Variable(t1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  2.5000\n",
      " 12.5000\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mean through a specific axis\n",
    "v= tr.mean(v1*v1,dim=1)\n",
    "print(v.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 0.5000  0.5000\n",
      " 0.5000  0.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=Variable(tr.ones(2,2),requires_grad=True)\n",
    "y=tr.mul(x,x)\n",
    "out = tr.mean(y)\n",
    "print(out)\n",
    "out.backward(tr.FloatTensor([1])) # or out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 0.2000  0.2000\n",
      " 0.2000  0.2000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=Variable(tr.ones(2,2),requires_grad=True)\n",
    "y=tr.mul(x,x)\n",
    "# 0.1 is learning rate, multiplied before gradient.\n",
    "y.backward(tr.FloatTensor([[0.1,0.1],[0.1,0.1]]))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "\n",
      "Columns 13 to 19 \n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "[torch.FloatTensor of size 20x20]\n",
      "\n",
      "\n",
      "    1     0     1     0     1     1     1     1     1     0\n",
      "    1     0     0     0     0     1     1     1     0     0\n",
      "    0     0     0     0     1     0     1     0     1     0\n",
      "    0     0     0     1     1     1     0     0     1     0\n",
      "    1     1     0     0     1     1     1     1     0     0\n",
      "    0     0     1     0     1     1     0     1     1     0\n",
      "    1     1     0     1     1     0     0     1     0     0\n",
      "    0     1     1     1     1     1     1     0     1     0\n",
      "    0     1     1     0     1     0     0     0     0     0\n",
      "    0     1     1     1     0     0     1     0     0     0\n",
      "    1     1     1     0     1     0     0     0     0     0\n",
      "    0     0     1     0     1     1     1     1     1     0\n",
      "    1     1     0     0     1     0     0     1     1     1\n",
      "    0     0     0     0     1     1     0     0     0     0\n",
      "    1     0     1     0     0     0     1     1     0     1\n",
      "    1     1     1     1     1     0     0     0     1     0\n",
      "    0     0     0     1     0     1     0     0     1     0\n",
      "    0     1     1     1     0     0     1     0     1     0\n",
      "    0     1     1     0     0     0     0     0     1     0\n",
      "    0     1     0     0     0     0     0     1     1     0\n",
      "[torch.FloatTensor of size 20x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.feature_data = np.ones((1000,20),dtype='float32')\n",
    "        self.length = 1000\n",
    "        self.label_data = np.random.randint(low=0,high=2,size=(1000,10)).astype('float32')\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        data = (self.feature_data[idx],self.label_data[idx])\n",
    "        return data\n",
    "data = myDataset()\n",
    "dataiter = DataLoader(data,batch_size=20,shuffle=False)\n",
    "print('======')\n",
    "for batch_id,(X,Y_) in enumerate(dataiter):\n",
    "    print(X)\n",
    "    print(Y_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([100, 20])\n",
      "torch.Size([98, 20])\n",
      "when the rest of data is not enough for a batch, all of the rest will be returned\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.feature_data = np.ones((998,20),dtype='float32')\n",
    "        self.length = 998\n",
    "        self.label_data = np.random.randint(low=0,high=2,size=(1000,10)).astype('float32')\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        data = (self.feature_data[idx],self.label_data[idx])\n",
    "        return data\n",
    "data = myDataset()\n",
    "dataiter = DataLoader(data,batch_size=100,shuffle=False)\n",
    "print('======')\n",
    "for X,y_ in dataiter:\n",
    "    print(X.size())\n",
    "print('when the rest of data is not enough for a batch, all of the rest will be returned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 0.0)\n",
      "================\n",
      "(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32), 1.0)\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "\n",
      "Columns 13 to 19 \n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "[torch.FloatTensor of size 20x20]\n",
      "\n",
      "\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 1\n",
      "[torch.FloatTensor of size 20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.feature_data = np.ones((1000,20),dtype='float32')\n",
    "        self.length = 1000\n",
    "        self.label_data = np.random.randint(low=0,high=2,size=(1000,)).astype('float32')\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        data = (self.feature_data[idx],self.label_data[idx])\n",
    "        print('================')\n",
    "        print(data)\n",
    "        return data\n",
    "data = myDataset()\n",
    "dataiter = DataLoader(data,batch_size=20,shuffle=False)\n",
    "print('======')\n",
    "for X,Y_ in dataiter:\n",
    "    print(X)\n",
    "    print(Y_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initiate Dataset from outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "\n",
      "Columns 13 to 19 \n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "    1     1     1     1     1     1     1\n",
      "[torch.FloatTensor of size 20x20]\n",
      "\n",
      "\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      "[torch.FloatTensor of size 20]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "        self.feature_data = features\n",
    "        self.length = len(features)\n",
    "        self.label_data = labels \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    def __getitem__(self,idx):\n",
    "        data = (self.feature_data[idx],self.label_data[idx])\n",
    "        return data\n",
    "\n",
    "features = np.ones((1000,20),dtype='float32')\n",
    "labels = np.random.randint(low=0,high=2,size=(1000,)).astype('float32')\n",
    "\n",
    "data = myDataset(features, labels)\n",
    "dataiter = DataLoader(data,batch_size=20,shuffle=False)\n",
    "for X,Y_ in dataiter:\n",
    "    print(X)\n",
    "    print(Y_)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## complete sample of Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "# TODO: need to normalize data\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.length = len(data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        instance = self.data[index]\n",
    "        return instance\n",
    "\n",
    "class DataFeeder:\n",
    "    def __init__(self,data_config):\n",
    "        self.data_config = data_config\n",
    "        self.train_data,self.test_data=self.loader()\n",
    "\n",
    "    def loader(self):\n",
    "        with open(self.data_config['data_filePath'],'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data['train_data'], data['test_data']\n",
    "\n",
    "    def train_feeder(self):\n",
    "        dataiter = DataLoader(myDataset(self.train_data),batch_size=self.data_config['batch_size'],shuffle='True')\n",
    "        return enumerate(dataiter)\n",
    "\n",
    "    def test_feeder(self):\n",
    "        data = DataLoader(myDataset(self.test_data),batch_size=len(self.test_data),shuffle='True')\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat&expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  2  3\n",
      " 1  2  3\n",
      " 1  2  3\n",
      " 1  2  3\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "t = tr.Tensor([[1,2,3]])\n",
    "t = t.repeat(4,1)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# +, - , *, /, reduce sum, reduce max, reduce mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mul\n",
      " \n",
      "(0 ,.,.) = \n",
      "  2  2  2  2\n",
      "  2  2  2  2\n",
      "  2  2  2  2\n",
      "\n",
      "(1 ,.,.) = \n",
      "  2  2  2  2\n",
      "  2  2  2  2\n",
      "  2  2  2  2\n",
      "\n",
      "(2 ,.,.) = \n",
      "  2  2  2  2\n",
      "  2  2  2  2\n",
      "  2  2  2  2\n",
      "[torch.FloatTensor of size 3x3x4]\n",
      "\n",
      "subtract\n",
      " \n",
      "(0 ,.,.) = \n",
      " -1 -1 -1 -1\n",
      " -1 -1 -1 -1\n",
      " -1 -1 -1 -1\n",
      "\n",
      "(1 ,.,.) = \n",
      " -1 -1 -1 -1\n",
      " -1 -1 -1 -1\n",
      " -1 -1 -1 -1\n",
      "\n",
      "(2 ,.,.) = \n",
      " -1 -1 -1 -1\n",
      " -1 -1 -1 -1\n",
      " -1 -1 -1 -1\n",
      "[torch.FloatTensor of size 3x3x4]\n",
      "\n",
      "sqrt\n",
      " \n",
      " 1.4142  1.4142  1.4142  1.4142\n",
      " 1.4142  1.4142  1.4142  1.4142\n",
      " 1.4142  1.4142  1.4142  1.4142\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "reduce_sum\n",
      " \n",
      " 8\n",
      " 8\n",
      " 8\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "reduce_mean:\n",
      " \n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "reduce_mean size:\n",
      " torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "v1 = tr.Tensor(np.ones((3,3,4)))\n",
    "v2 = tr.Tensor(np.ones((3,4))*2)\n",
    "t = tr.mul(v1,v2)\n",
    "print('mul\\n',t)\n",
    "\n",
    "t = tr.add(v1,-v2)\n",
    "print('subtract\\n',t)\n",
    "\n",
    "t = tr.sqrt(v2)\n",
    "print('sqrt\\n',t)\n",
    "\n",
    "t = v2.sum(1)\n",
    "print('reduce_sum\\n',t)\n",
    "\n",
    "t = v1.mean(1)\n",
    "print('reduce_mean:\\n',t)\n",
    "print('reduce_mean size:\\n',t.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat&Expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 1  1  1\n",
      " 2  2  2\n",
      " 3  3  3\n",
      "[torch.FloatTensor of size 3x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "v1 = tr.Tensor(np.array([1,2,3]))\n",
    "v2 = tr.unsqueeze(v1,dim=1)\n",
    "print()\n",
    "v3 = v2.expand(-1,3)\n",
    "print(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
