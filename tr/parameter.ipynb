{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# type of parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paramter is a subclass of Variable. It can be registerd automatically in Module.\n",
      "=========\n",
      "Linear(in_features=3, out_features=4, bias=True)\n",
      "=========\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [3 x 4], m2: [2 x 3] at /opt/conda/conda-bld/pytorch-cpu_1518282373170/work/torch/lib/TH/generic/THTensorMath.c:1434",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c91170a83074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Paramter is a subclass of Variable. It can be registerd automatically in Module.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpara\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c91170a83074>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Paramter is a subclass of Variable. It can be registerd automatically in Module.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(tensor1, tensor2, out)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim_tensor1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdim_tensor2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [3 x 4], m2: [2 x 3] at /opt/conda/conda-bld/pytorch-cpu_1518282373170/work/torch/lib/TH/generic/THTensorMath.c:1434"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "class Net(tr.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.linears = tr.nn.ModuleList([tr.nn.Linear(3,4),tr.nn.Linear(4,6)])\n",
    "        self.W = tr.nn.Parameter(tr.FloatTensor(np.random.randn(3,4)),requires_grad=True)\n",
    "        self.W2 = tr.nn.Parameter(tr.FloatTensor(np.random.randn(3,4)),requires_grad=True)\n",
    "        print('=========')\n",
    "        print(self.linears[0])\n",
    "        print('=========')\n",
    "    \n",
    "    def forward(self):\n",
    "        X=tr.autograd.Variable(tr.FloatTensor(np.ones(shape=(2,3))))\n",
    "        return self.W.matmul(X)\n",
    "\n",
    "print('Paramter is a subclass of Variable. It can be registerd automatically in Module.')\n",
    "module = Net()\n",
    "t=module.forward()\n",
    "print(t.data.numpy())\n",
    "for name,para in list(module.named_parameters()):\n",
    "    print(name)\n",
    "    print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3  3  3\n",
      " 3  3  3  3\n",
      " 3  3  3  3\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n",
      "W\n",
      "Parameter containing:\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      " 1  1  1  1\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "class Net(tr.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.W = tr.nn.Parameter(tr.Tensor(np.ones((3,4))))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        z = tr.matmul(X,self.W)\n",
    "        return z\n",
    "\n",
    "module = Net()\n",
    "X = tr.autograd.Variable(tr.Tensor(np.ones((3,3),dtype='float32')),requires_grad=False)\n",
    "outputs = module(X)\n",
    "print(outputs)\n",
    "for name,para in list(module.named_parameters()):\n",
    "    print(name)\n",
    "    print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter will not be registered if it is created outside __init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3  3  3\n",
      " 3  3  3  3\n",
      " 3  3  3  3\n",
      "[torch.FloatTensor of size 3x4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "class Net(tr.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        W = tr.nn.Parameter(tr.Tensor(np.ones((3,4))))\n",
    "        z = tr.matmul(X,W)\n",
    "        return z\n",
    "\n",
    "module = Net()\n",
    "X = tr.autograd.Variable(tr.Tensor(np.ones((3,3),dtype='float32')),requires_grad=False)\n",
    "outputs = module(X)\n",
    "print(outputs)\n",
    "for name,para in list(module.named_parameters()):\n",
    "    print(name)\n",
    "    print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is forward function necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2838  0.0697 -0.0463  ...  -0.1900 -0.1006 -0.0856\n",
      "-0.1341  0.1609 -0.2762  ...   0.0939  0.1497 -0.0938\n",
      "-0.2266  0.0573  0.2459  ...   0.0056 -0.1942  0.2193\n",
      "          ...             ⋱             ...          \n",
      " 0.2126  0.0881  0.1800  ...   0.0983 -0.1551 -0.2113\n",
      "-0.2789 -0.2155  0.2749  ...   0.2006 -0.2932  0.0632\n",
      "-0.2642 -0.1219  0.2691  ...  -0.2087 -0.0072  0.2242\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2858  0.0702 -0.0440  ...  -0.1807 -0.1035 -0.0842\n",
      "-0.1248  0.1598 -0.2843  ...   0.1005  0.1557 -0.0893\n",
      "-0.2326  0.0561  0.2445  ...   0.0003 -0.1931  0.2189\n",
      "          ...             ⋱             ...          \n",
      " 0.2125  0.0881  0.1801  ...   0.0981 -0.1551 -0.2113\n",
      "-0.2787 -0.2155  0.2748  ...   0.2004 -0.2931  0.0631\n",
      "-0.2641 -0.1218  0.2691  ...  -0.2088 -0.0072  0.2240\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2877  0.0708 -0.0417  ...  -0.1714 -0.1063 -0.0828\n",
      "-0.1155  0.1586 -0.2924  ...   0.1071  0.1616 -0.0848\n",
      "-0.2386  0.0549  0.2430  ...  -0.0049 -0.1919  0.2184\n",
      "          ...             ⋱             ...          \n",
      " 0.2124  0.0881  0.1802  ...   0.0980 -0.1551 -0.2113\n",
      "-0.2786 -0.2154  0.2747  ...   0.2002 -0.2930  0.0630\n",
      "-0.2640 -0.1218  0.2690  ...  -0.2088 -0.0073  0.2238\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2896  0.0714 -0.0394  ...  -0.1621 -0.1092 -0.0813\n",
      "-0.1063  0.1575 -0.3005  ...   0.1138  0.1676 -0.0803\n",
      "-0.2447  0.0538  0.2416  ...  -0.0101 -0.1907  0.2180\n",
      "          ...             ⋱             ...          \n",
      " 0.2123  0.0881  0.1803  ...   0.0978 -0.1551 -0.2113\n",
      "-0.2784 -0.2153  0.2747  ...   0.2000 -0.2929  0.0629\n",
      "-0.2638 -0.1217  0.2689  ...  -0.2089 -0.0073  0.2236\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2916  0.0719 -0.0371  ...  -0.1528 -0.1121 -0.0799\n",
      "-0.0970  0.1564 -0.3086  ...   0.1204  0.1735 -0.0758\n",
      "-0.2507  0.0526  0.2402  ...  -0.0153 -0.1895  0.2176\n",
      "          ...             ⋱             ...          \n",
      " 0.2122  0.0881  0.1804  ...   0.0977 -0.1551 -0.2113\n",
      "-0.2783 -0.2153  0.2746  ...   0.1999 -0.2928  0.0628\n",
      "-0.2637 -0.1217  0.2688  ...  -0.2090 -0.0074  0.2234\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2935  0.0725 -0.0348  ...  -0.1435 -0.1150 -0.0785\n",
      "-0.0877  0.1552 -0.3167  ...   0.1270  0.1794 -0.0713\n",
      "-0.2567  0.0515  0.2387  ...  -0.0205 -0.1884  0.2171\n",
      "          ...             ⋱             ...          \n",
      " 0.2121  0.0881  0.1805  ...   0.0975 -0.1551 -0.2113\n",
      "-0.2781 -0.2152  0.2745  ...   0.1997 -0.2927  0.0627\n",
      "-0.2636 -0.1217  0.2687  ...  -0.2090 -0.0074  0.2232\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2954  0.0731 -0.0325  ...  -0.1342 -0.1178 -0.0771\n",
      "-0.0785  0.1541 -0.3248  ...   0.1336  0.1854 -0.0668\n",
      "-0.2627  0.0503  0.2373  ...  -0.0257 -0.1872  0.2167\n",
      "          ...             ⋱             ...          \n",
      " 0.2120  0.0881  0.1806  ...   0.0974 -0.1551 -0.2113\n",
      "-0.2779 -0.2151  0.2745  ...   0.1995 -0.2926  0.0627\n",
      "-0.2635 -0.1216  0.2687  ...  -0.2091 -0.0075  0.2230\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2974  0.0736 -0.0302  ...  -0.1249 -0.1207 -0.0756\n",
      "-0.0692  0.1530 -0.3328  ...   0.1402  0.1913 -0.0623\n",
      "-0.2686  0.0492  0.2358  ...  -0.0310 -0.1860  0.2163\n",
      "          ...             ⋱             ...          \n",
      " 0.2119  0.0881  0.1807  ...   0.0972 -0.1551 -0.2113\n",
      "-0.2778 -0.2151  0.2744  ...   0.1993 -0.2925  0.0626\n",
      "-0.2633 -0.1216  0.2686  ...  -0.2092 -0.0075  0.2228\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.2993  0.0742 -0.0280  ...  -0.1156 -0.1236 -0.0742\n",
      "-0.0600  0.1518 -0.3409  ...   0.1469  0.1972 -0.0579\n",
      "-0.2746  0.0480  0.2344  ...  -0.0362 -0.1848  0.2158\n",
      "          ...             ⋱             ...          \n",
      " 0.2118  0.0881  0.1807  ...   0.0971 -0.1551 -0.2113\n",
      "-0.2776 -0.2150  0.2743  ...   0.1991 -0.2924  0.0625\n",
      "-0.2632 -0.1215  0.2685  ...  -0.2093 -0.0076  0.2226\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n",
      "linears.0.weight\n",
      "Parameter containing:\n",
      "-0.3012  0.0748 -0.0257  ...  -0.1063 -0.1264 -0.0728\n",
      "-0.0508  0.1507 -0.3489  ...   0.1534  0.2031 -0.0534\n",
      "-0.2806  0.0469  0.2329  ...  -0.0414 -0.1837  0.2154\n",
      "          ...             ⋱             ...          \n",
      " 0.2117  0.0881  0.1808  ...   0.0969 -0.1551 -0.2113\n",
      "-0.2775 -0.2149  0.2743  ...   0.1989 -0.2923  0.0624\n",
      "-0.2631 -0.1215  0.2684  ...  -0.2093 -0.0076  0.2224\n",
      "[torch.FloatTensor of size 100x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class Net(tr.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.linears = tr.nn.ModuleList([tr.nn.Linear(10,100),tr.nn.Linear(10,50)])\n",
    "    \n",
    "    def forward_softmax(self,X):\n",
    "        linear_layer = self.linears[0](X)\n",
    "        outputs = F.log_softmax(linear_layer,dim=1)\n",
    "        return outputs\n",
    "    \n",
    "    def cross_entropy_loss(self,score,target):\n",
    "        loss = tr.nn.NLLLoss(size_average=True,reduce=True)\n",
    "        return loss(score,target)\n",
    "        \n",
    "    \n",
    "\n",
    "# \n",
    "def optimizer(module):\n",
    "    optim = tr.optim.SGD(module.parameters(),lr=0.03,weight_decay=0.0003)\n",
    "    return optim\n",
    "    \n",
    "module = Net()\n",
    "optim = optimizer(module)\n",
    "X = tr.autograd.Variable(tr.Tensor(np.random.randn(30,10)),requires_grad=False)\n",
    "y_ = tr.autograd.Variable(tr.LongTensor(np.random.randint(low=0,high=3,size=(30))))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    optim.zero_grad()\n",
    "    score = module.forward_softmax(X)\n",
    "    loss = module.cross_entropy_loss(score,y_)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    for i,j in module.named_parameters():\n",
    "        if i == 'linears.0.weight':\n",
    "            print(i)\n",
    "            print(j)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
